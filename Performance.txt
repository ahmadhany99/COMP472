Using a Multinomial Naive Bayes Classifier (naive bayes.MultinomialNB.html) with the default parameters.

For emotions : 

                precision    recall  f1-score   support

    admiration       0.48      0.44      0.46      2127
     amusement       0.52      0.29      0.37      1307
         anger       0.36      0.11      0.17      1035
     annoyance       0.18      0.07      0.10      1599
      approval       0.24      0.09      0.13      2214
        caring       0.29      0.06      0.10       723
     confusion       0.33      0.05      0.09      1022
     curiosity       0.38      0.10      0.16      1174
        desire       0.40      0.04      0.07       396
disappointment       0.27      0.04      0.07       895
   disapproval       0.24      0.08      0.12      1511
       disgust       0.46      0.08      0.13       583
 embarrassment       0.11      0.00      0.01       264
    excitement       0.30      0.04      0.07       593
          fear       0.58      0.03      0.06       366
     gratitude       0.73      0.66      0.70      1440
         grief       1.00      0.00      0.00        64
           joy       0.35      0.11      0.17       868
          love       0.66      0.37      0.47      1009
   nervousness       0.00      0.00      0.00       162
       neutral       0.37      0.84      0.51     11108
      optimism       0.42      0.13      0.19       911
         pride       0.00      0.00      0.00       156
   realization       0.26      0.04      0.07       928
        relief       0.00      0.00      0.00       143
       remorse       0.58      0.09      0.15       284
       sadness       0.43      0.08      0.14       779
      surprise       0.31      0.06      0.10       703

      accuracy                           0.39     34364
     macro avg       0.37      0.14      0.16     34364
  weighted avg       0.37      0.39      0.31     34364

Confusion Matrix: 
 [[ 939   15    1   10   44    1    0   12    0    3    6    1    0    3
     0   42    0   15   34    0  974   11    0    2    0    0    1   13]
 [  37  377    4   12   12    0    1    1    0    0    5    0    0    4
     0    9    0   13    6    0  815    2    0    2    0    0    0    7]
 [  17   12  119   64    3    3    1    7    1    6   20    6    0    1
     0    2    0    1    3    0  761    1    0    2    0    1    3    1]
 [  29   21   52  107   25    6    3    9    0    5   36    6    0    0
     1   14    0    1    2    0 1262    6    0    3    0    0    9    2]
 [ 105   18    5   27  189   13    8    4    3    3   31    2    0    3
     0   11    0    7   11    0 1743   20    0    8    0    0    1    2]
 [  16    0    0    6   17   45    2    2    0    1    3    0    0    0
     0   22    0    5    5    0  586   12    0    0    0    0    1    0]
 [  13    7    1    7   20    0   56   30    0    2   18    1    0    0
     0    7    0    3    1    0  851    2    0    2    0    0    0    1]
 [  17    6    2    7   16    1   15  118    1    1    4    0    0    0
     0    7    0    1    1    0  968    2    0    2    0    0    2    3]
 [  13    5    1    4    8    3    1    1   16    0    2    0    0    1
     0    3    0    3    3    0  317   15    0    0    0    0    0    0]
 [  20    5    6   26   17    3    4    2    1   34   22    5    0    1
     1    3    0    2    0    1  730    2    0    4    0    2    4    0]
 [  18   18    7   24   39    2    9    5    0    6  123    5    2    0
     1    8    0    1    1    0 1228    3    0    4    1    0    5    1]
 [  11    2   27   34    6    0    1    2    0    2   15   45    1    0
     0    1    0    1    3    0  425    3    0    1    0    1    1    1]
 [   5    2    2   10    4    0    1    0    0    1    3    1    1    0
     0    2    0    2    2    0  221    1    0    3    0    1    2    0]
 [  58    4    3    8   15    1    0    5    0    0    3    2    0   24
     0   14    0   43    9    0  395    2    0    2    1    0    1    3]
 [  12    5    0    7    5    1    0    2    0    5    6    4    0    0
    11    0    0    0    0    0  298    1    0    2    0    0    3    4]
 [  78    7    0    2    8    6    0    1    1    1    2    0    0    0
     0  957    0   14    2    0  346   12    0    0    0    1    1    1]
 [   0    0    0    3    0    2    0    0    0    0    0    0    0    0
     0    1    0    0    0    0   55    1    0    0    0    0    2    0]
 [  70   53    1    6   17    1    1    0    1    1    1    0    0    7
     0   26    0   98   20    0  559    3    0    3    0    0    0    0]
 [  72    8    0    2    9    0    1    4    0    1    2    0    0    0
     0    8    0    4  371    0  524    2    0    0    0    0    1    0]
 [   1    0    1    2    6    0    0    1    0    3    2    0    0    0
     0    0    0    0    0    0  143    0    0    0    0    0    2    1]
 [ 315  129   83  157  262   41   46   84   14   32  164   19    1   35
     4   86    0   42   77    0 9338   52    1   51    0    3   31   41]
 [  44    7    0    4   18   13    3    2    1    1    5    0    0    1
     0   26    0   10    3    0  655  115    0    1    0    0    1    1]
 [  16    2    0    2    3    0    0    0    0    0    3    0    0    0
     0    3    0    2    0    0  123    0    0    2    0    0    0    0]
 [  12    4    3   20   26    0    6    2    0    4   12    1    2    0
     0    3    0    2    3    0  775    2    0   37    0    1    1   12]
 [   8    0    1    2    1    2    1    0    0    1    0    0    0    0
     0    9    0    3    1    0  112    1    0    1    0    0    0    0]
 [   2    1    1    4    5    3    0    0    0    1    3    0    2    0
     0   20    0    1    1    0  202    0    0    0    0   25   13    0]
 [   2    5    4   12   12    5    2    0    1   10    7    0    0    1
     1   15    0    2    2    0  619    3    0    4    0    8   64    0]
 [  38   11    8   18    7    2    6   14    0    2    7    0    0    0
     0    5    0    1    3    0  532    0    0    5    1    0    0   43]]
     
For sentiments : 

              precision    recall  f1-score   support

   ambiguous       0.42      0.24      0.31      3827
    negative       0.53      0.52      0.52      7542
     neutral       0.49      0.49      0.49     11108
    positive       0.62      0.71      0.66     11887

    accuracy                           0.54     34364
   macro avg       0.51      0.49      0.49     34364
weighted avg       0.53      0.54      0.54     34364

Confusion Matrix: 
 [[ 916  631 1402  878]
 [ 272 3921 2077 1272]
 [ 686 1964 5421 3037]
 [ 300  941 2187 8459]]


Using a Decision Tree (tree.DecisionTreeClassifier) with the default parameters.

For emotions : 
                precision    recall  f1-score   support
    admiration       0.42      0.58      0.49      2076
     amusement       0.42      0.59      0.49      1246
         anger       0.24      0.39      0.30      1011
     annoyance       0.16      0.22      0.18      1726
      approval       0.20      0.26      0.23      2249
        caring       0.20      0.25      0.22       685
     confusion       0.22      0.28      0.24       978
     curiosity       0.34      0.36      0.35      1203
        desire       0.22      0.27      0.24       399
disappointment       0.15      0.16      0.15       930
   disapproval       0.23      0.24      0.23      1492
       disgust       0.24      0.20      0.22       596
 embarrassment       0.20      0.15      0.17       289
    excitement       0.24      0.22      0.23       620
          fear       0.33      0.30      0.31       345
     gratitude       0.76      0.74      0.75      1346
         grief       0.06      0.07      0.06        59
           joy       0.31      0.24      0.27       884
          love       0.57      0.52      0.55       987
   nervousness       0.17      0.11      0.13       169
       neutral       0.51      0.43      0.46     11171
      optimism       0.38      0.22      0.28       884
         pride       0.09      0.04      0.06       144
   realization       0.19      0.08      0.11       938
        relief       0.22      0.14      0.18       153
       remorse       0.44      0.27      0.33       319
       sadness       0.34      0.20      0.25       771
      surprise       0.36      0.23      0.28       694
      accuracy                           0.36     34364
     macro avg       0.29      0.28      0.28     34364
  weighted avg       0.38      0.36      0.36     34364
Confusion Matrix: 
 [[1206   49   15   31  118   21   10   18   11   22   21    7    2   32
     7   53    1   43   76    5  248   22   14   12    5    1    3   23]
 [  55  738   28   40   30    7   14   10    7    8   24    8    4   13
     1   10    0   61    7    0  154    3    0   11    2    2    0    9]
 [  19   26  395  155   38   12   17   17    4   23   45   33    5    2
     8    2    1    3    0    1  186    2    0    5    1    0    6    5]
 [  48   69  214  379  122   31   46   52   13   77  116   61   13   10
     7   14    2    9    8    4  364   10    0   13    3    4   22   15]
 [ 193   70   62  150  594   62   42   23   33   36   70   18    7   18
     9   18    2   32   31    3  659   38    5   28   14    1   15   16]
 [  36   12   21   44   75  171    6    6   10   14   13    4    2    3
     5   11    2    8   11    3  178   28    1    2    7    6    5    1]
 [  19   23   31   62   66   15  271  129    0   13   25    3    2    9
     6    3    1    3    9    4  259    3    0   14    0    4    1    3]
 [  41   17   27   61   52   13  178  438    4   17   22    6    7   22
     2    8    0    4    4    1  245    7    1    6    1    0    1   18]
 [  17   14    5   18   33   13    6    9  107   10   14    1    2    8
     1    3    0    3    9    5   96   18    2    4    0    0    0    1]
 [  20   24   56  113   64   18   30   18   10  151   66   23    4    6
     5    6    3    5    6    7  208   10    1    5    2    9   44   16]
 [  28   32   79  168  114   27   57   31   13   64  353   25   16    9
    10    6    0    7    6    2  379    9    1   23    1    5   19    8]
 [  10   21   68   99   38    4   12    6    3   22   35  119    7    2
    11    1    1    3    3    1  112    3    0    6    0    0    6    3]
 [   4   17   19   36   15    7    9    5    2   10    8   13   44    2
     3    2    0    1    3    2   70    2    0    3    0    2    5    5]
 [  88   30   15   22   39    8    6   19   13    8    6    1    0  136
     4   12    0   35   10    1  117   11    1    7    2    0    4   25]
 [   5    7   15   28   23    7    6   10    2   18   10   16    1    0
   103    2    2    0    0    4   65    3    1    4    0    0   11    2]
 [ 112    7    5   19   22   16    5    8    7   11    7    2    1   12
     0  994    0   21    7    0   53   13    2    2    4   13    1    2]
 [   1    0    4    2    1    2    1    1    1    5    1    5    0    0
     2    1    4    1    0    2   13    0    0    2    0    2    7    1]
 [ 127   99    1   17   55   17    3    7   12   10   12    1    3   45
     3   25    1  214   41    0  142   16    6    8    8    0    4    7]
 [ 119   22    5   14   56   23    9    7   14    5   13    2    0   18
     1    8    1   45  517    0   94    6    0    2    4    1    1    0]
 [   3    4    9   10   18   11    8    3    0   13    3    1    6    2
    13    0    0    1    0   18   38    1    0    2    0    1    2    2]
 [ 511  362  446  733 1081  260  405  393  144  318  518  119   52  156
    78   85   26  131  124   29 4768   93   17  116   17   14   87   88]
 [  63   23   14   34   80   35   14   13   52   16   28    4    3   10
     8   18    1   10   10    1  238  198    2    4    1    1    1    2]
 [  30    4    6    7   16    2    2    0    1    3    1    2    1    5
     0    3    0    8    1    0   39    4    6    1    0    0    1    1]
 [  36   32   25   74  123   14   32   16   13   48   47    6    9    4
     8    4    2   12    5    4  307    7    5   74    1    3    6   21]
 [  10    5    2    5   21    7    1    2    1    3    5    2    0    1
     0   10    0    9    1    0   39    4    1    0   22    0    2    0]
 [   5    5   11   17   11   13    6    3    4   21   13    0   14    0
     2   10    5    2    2    2   43    2    0    9    1   85   32    1]
 [  10   12   22   57   46   24    8   15    8   76   40   15    9    1
     8    6   13    4    6   10  169    6    0   13    0   40  152    1]
 [  50   21   31   24   36    3   31   44    5   19   18    4    9   35
     7    1    1    7    3    0  157    8    1   14    2    0    5  158]]
     
For sentiments : 
              precision    recall  f1-score   support
   ambiguous       0.35      0.49      0.41      3846
    negative       0.51      0.59      0.55      7783
     neutral       0.51      0.47      0.49     11041
    positive       0.71      0.59      0.64     11694
    accuracy                           0.54     34364
   macro avg       0.52      0.54      0.52     34364
weighted avg       0.56      0.54      0.55     34364
Confusion Matrix: 
 [[1879  631  898  438]
 [ 927 4616 1486  754]
 [1643 2519 5211 1668]
 [ 894 1315 2570 6915]]
 
Using a better performing Naive Bayes Classifier model using GridSearchCV with the parameter 'alpha'. 

For emotions :
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
For emotions : 

                precision    recall  f1-score   support

    admiration       0.47      0.50      0.48      2141
     amusement       0.51      0.44      0.47      1199
         anger       0.28      0.17      0.21       991
     annoyance       0.18      0.10      0.13      1667
      approval       0.24      0.13      0.17      2242
        caring       0.25      0.14      0.18       732
     confusion       0.25      0.13      0.17       943
     curiosity       0.34      0.18      0.24      1243
        desire       0.36      0.11      0.16       421
disappointment       0.22      0.08      0.12       992
   disapproval       0.20      0.12      0.15      1519
       disgust       0.33      0.14      0.20       567
 embarrassment       0.38      0.05      0.08       294
    excitement       0.31      0.09      0.14       639
          fear       0.33      0.09      0.14       370
     gratitude       0.71      0.74      0.73      1414
         grief       0.00      0.00      0.00        72
           joy       0.37      0.21      0.27       861
          love       0.58      0.47      0.52       998
   nervousness       0.33      0.01      0.01       162
       neutral       0.39      0.72      0.51     10973
      optimism       0.42      0.25      0.31       921
         pride       0.00      0.00      0.00       146
   realization       0.21      0.08      0.11       948
        relief       0.17      0.01      0.01       141
       remorse       0.50      0.18      0.26       289
       sadness       0.34      0.17      0.22       786
      surprise       0.39      0.20      0.26       693

      accuracy                           0.39     34364
     macro avg       0.32      0.20      0.22     34364
  weighted avg       0.36      0.39      0.35     34364

Confusion Matrix: 
 [[1076   16    4   14   47    6    4   16    1    3   11    2    0   12
     1   60    0   31   63    0  722   23    0    6    0    1    4   18]
 [  42  531    7   33   22    4    6    7    2    2   10    3    1    8
     0    5    0   29   11    0  450    6    0   11    0    0    1    8]
 [  24   11  167  112   18    4    4   11    2   12   21   15    0    5
     0    6    0    4    3    0  551    6    0    5    0    0    9    1]
 [  30   36   77  167   61   21   17   23    1   26   77   22    2    3
     5   20    0    2    8    0 1021   10    0   12    1    2   16    7]
 [ 132   31   12   37  297   24   21   23    4   20   54    7    0    5
     2   27    0   19   32    0 1424   28    0   18    0    2   16    7]
 [  15    4    4   13   25  101    1    7    1    7    9    0    0    3
     0   18    0    9   10    0  471   17    0    6    0    4    6    1]
 [  15   14   11   19   28    2  122   57    0    6   22    1    0    0
     1    2    0    2    4    0  612    6    0    7    0    0    2   10]
 [  25   12   12   20   29    8   42  224    2    6   24    1    0    5
     0    6    0    3    6    0  791    6    0    9    0    1    0   11]
 [   9    7    2    7   15    5    2    6   45    1    4    2    0    3
     0    6    0    5    7    0  266   25    0    0    0    0    1    3]
 [  20    7   11   35   27   17   12    5    2   80   32    4    0    4
     1    8    0    4    7    0  642    8    0   14    0    4   41    7]
 [  25   12   35   53   63   12   25    6    3   23  185   16    2    1
     2    9    0    6    7    0  989    9    0   11    0    2   14    9]
 [  15    3   38   46   11    2   10    3    0    7   27   82    3    1
    12    1    0    1    4    0  277    2    1    7    0    0    7    7]
 [   6    5    6   19    3    4    8    2    1    3    9    4   14    1
     0    2    0    0    3    0  181    1    0    8    0    1    7    6]
 [  86   16    8    4   23    3    5   12    1    1    6    1    0   56
     0   17    0   42   16    0  304   13    0    4    0    0    4   17]
 [   9    5    0   13    8    3    7    6    1    3    7    9    1    2
    34    0    0    1    0    0  239    3    1    4    0    0    6    8]
 [  75   13    1    5   15    7    4    2    1    4    5    0    0    4
     0 1050    0   27    6    0  167   16    0    1    0    5    5    1]
 [   1    1    1    1    1    1    2    0    0    0    0    0    0    0
     0    0    0    0    1    1   50    0    0    1    0    2    9    0]
 [  65   82    1    8   21    8    0    7    0    4    3    1    1   11
     2   41    0  184   39    0  367    5    0    4    1    1    1    4]
 [  99    9    4    5   11    2    1    3    2    4    2    0    0    3
     0   13    0   15  472    0  343    5    0    2    0    0    1    2]
 [   4    1    2    4    7    4    4    2    0    4    3    0    0    1
     2    2    0    0    2    1  115    1    0    0    0    0    3    0]
 [ 357  188  168  238  377  119  159  188   38   87  323   65    9   40
    36  106    3   71  103    1 7908  106    6  123    2    8   71   73]
 [  49    7    1    7   48   22    9    9   13    4    5    2    0    4
     1   23    0   10    5    0  466  229    1    4    0    1    1    0]
 [  30    1    3    1   13    3    3    1    1    1    4    0    0    0
     0    4    0    3    2    0   74    1    0    1    0    0    0    0]
 [  25   12    2   25   33    8   11    8    0   10   35    5    3    1
     0    5    0    6    2    0  651    9    0   72    1    2    8   14]
 [  11    1    2    2    8    3    1    1    0    1    1    0    0    1
     0   10    0    8    0    0   81    5    0    0    1    0    2    2]
 [   6    1    0    2    6    8    0    1    2   10    2    1    0    0
     0   15    0    0    2    0  151    1    0    4    0   52   25    0]
 [   4   12    6   27   16    9    3    3    3   32   19    4    1    0
     2   11    0    4    1    0  468    6    0    4    0   17  132    2]
 [  52   10   11   18   12    2    9   19    0    4    9    4    0    8
     1    5    0    7    4    0  369    4    0    7    0    0    1  137]]
     
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
C:\Users\Admin\anaconda3\envs\comp472_A1\lib\site-packages\sklearn\naive_bayes.py:591: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10
  warnings.warn(
  
For sentiments : 

              precision    recall  f1-score   support

   ambiguous       0.42      0.24      0.30      3706
    negative       0.54      0.52      0.53      7687
     neutral       0.49      0.49      0.49     11112
    positive       0.62      0.70      0.66     11859

    accuracy                           0.55     34364
   macro avg       0.52      0.49      0.50     34364
weighted avg       0.54      0.55      0.54     34364

Confusion Matrix: 
 [[ 893  583 1373  857]
 [ 304 4006 2089 1288]
 [ 650 1928 5499 3035]
 [ 303  918 2281 8357]]

 
Using a better performing Decision Tree model using GridSearchCV with parameters 'criterion', 'max_depth' and 'min_samples_split'. 

For emotions : 
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support
    admiration       0.36      0.21      0.27      2105
     amusement       0.56      0.34      0.42      1220
         anger       0.50      0.00      0.00      1105
     annoyance       0.08      0.00      0.00      1669
      approval       0.12      0.00      0.00      2285
        caring       0.25      0.00      0.01       668
     confusion       0.00      0.00      0.00       995
     curiosity       0.00      0.00      0.00      1207
        desire       0.39      0.20      0.26       433
disappointment       0.00      0.00      0.00       932
   disapproval       0.00      0.00      0.00      1465
       disgust       0.00      0.00      0.00       613
 embarrassment       0.00      0.00      0.00       285
    excitement       0.19      0.01      0.03       616
          fear       0.00      0.00      0.00       337
     gratitude       0.88      0.71      0.79      1446
         grief       0.00      0.00      0.00        61
           joy       0.36      0.21      0.26       836
          love       0.58      0.58      0.58       984
   nervousness       0.00      0.00      0.00       163
       neutral       0.36      0.93      0.52     11102
      optimism       0.47      0.28      0.35       827
         pride       0.00      0.00      0.00       145
   realization       0.00      0.00      0.00       957
        relief       0.00      0.00      0.00       148
       remorse       0.41      0.52      0.46       301
       sadness       0.42      0.01      0.01       779
      surprise       0.00      0.00      0.00       680
      accuracy                           0.39     34364
     macro avg       0.21      0.14      0.14     34364
  weighted avg       0.29      0.39      0.27     34364
Confusion Matrix: 
 [[  446    11     0     0     1     0     0     0     7     0     0     0
      0     1     0    12     0    35    75     0  1490    23     0     0
      0     3     1     0]
 [   22   414     0     2     1     0     0     0     2     0     0     0
      0     2     0     3     0     7     6     0   748     9     0     0
      0     4     0     0]
 [   20     8     1     0     0     0     0     0     1     0     0     0
      0     0     0     4     0     5    11     0  1048     3     0     0
      0     4     0     0]
 [   21    32     0     1     0     0     0     0     5     0     0     0
      0     0     0    12     0     9    14     0  1563     8     0     0
      0     4     0     0]
 [   94    11     0     0     1     0     0     0     9     0     1     0
      0     0     0     9     0    20    26     0  2089    18     0     0
      0     7     0     0]
 [   23     4     0     0     0     2     0     0     6     0     0     0
      0     0     0     6     0    14    17     0   548    32     0     0
      0    15     1     0]
 [   11    12     1     0     0     0     0     0     0     0     1     0
      0     0     0     2     0     8     4     0   953     1     0     0
      0     2     0     0]
 [   18     9     0     0     1     0     0     0     3     0     0     0
      0     0     0     5     0     4    11     0  1144     4     0     0
      0     8     0     0]
 [    5     4     0     0     0     0     0     0    85     1     0     0
      0     0     0     1     0     1    14     0   295    26     0     0
      1     0     0     0]
 [   29     5     0     2     0     0     0     0     5     0     0     0
      0     0     0     3     0     4     8     0   858     9     0     0
      0     9     0     0]
 [   34    11     0     0     0     0     0     0     5     0     0     0
      0     0     0     5     0     3    10     0  1382     7     0     0
      0     8     0     0]
 [    3     3     0     0     0     0     0     0     1     0     0     0
      0     0     0     1     0     2     6     0   586     5     0     0
      0     6     0     0]
 [    3     4     0     0     0     0     0     0     0     0     0     0
      0     0     0     1     0     1     0     0   267     0     0     0
      0     9     0     0]
 [   24    11     0     0     1     0     0     0     3     0     0     0
      0     9     0     3     0    33    12     0   516     4     0     0
      0     0     0     0]
 [    3     5     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     1     4     0   323     1     0     0
      0     0     0     0]
 [   59     7     0     2     0     0     0     0     3     0     2     0
      0     5     0  1030     0    44     7     0   232    25     0     0
      0    29     1     0]
 [    1     0     0     0     0     1     0     0     1     0     0     0
      0     0     0     0     0     1     0     0    52     0     0     0
      0     5     0     0]
 [   47    30     0     0     0     0     0     0     3     0     0     0
      0    21     0     7     0   173    42     0   503     9     0     0
      0     1     0     0]
 [   14    10     0     1     0     0     3     0     1     2     1     0
      0     1     0     3     0     9   569     0   368     2     0     0
      0     0     0     0]
 [    1     0     0     0     1     0     0     0     0     0     0     0
      0     0     0     0     0     0     0     0   159     1     0     0
      0     1     0     0]
 [  233   124     0     3     1     0     0     0    41     3     1     0
      0     6     0    54     0    60   122     0 10360    57     0     0
      0    37     0     0]
 [   46     5     0     0     0     0     0     0    24     0     0     0
      0     0     0     3     0    11     5     0   498   232     0     0
      0     3     0     0]
 [   12     2     0     0     0     0     0     0     0     0     0     0
      0     0     0     0     0     9     0     0   121     1     0     0
      0     0     0     0]
 [   20     8     0     0     0     1     1     0     2     0     0     0
      0     0     0     3     0     3    10     0   899     4     0     0
      0     6     0     0]
 [   13     2     0     0     0     0     0     0     0     0     0     0
      0     0     0     9     0    12     0     0   112     0     0     0
      0     0     0     0]
 [    2     1     0     1     0     3     0     0     3     0     0     0
      0     0     0     0     0     0     3     0   126     1     0     0
      0   157     4     0]
 [   14     5     0     0     1     1     0     0     6     0     0     0
      0     0     0     0     0     7     6     0   663     6     0     0
      0    65     5     0]
 [   10     5     0     0     0     0     0     0     3     0     0     0
      0     3     0     1     0     5     2     0   648     1     0     0
      0     2     0     0]]
      
For sentiments : 
              precision    recall  f1-score   support
   ambiguous       0.44      0.00      0.01      3827
    negative       0.66      0.05      0.09      7653
     neutral       0.36      0.93      0.52     11130
    positive       0.77      0.34      0.47     11754
    accuracy                           0.43     34364
   macro avg       0.56      0.33      0.27     34364
weighted avg       0.58      0.43      0.35     34364
Confusion Matrix: 
 [[   19    23  3641   144]
 [    6   371  6930   346]
 [   12    61 10381   676]
 [    6   109  7624  4015]]

Part 3.4 

The overall hit rate is : 77.45063827339175 %
The overall miss rate is : 22.54936172660825 %

Part 3.8 First embedding model

Using a better performing Multi-Layered Perceptron (the best model)
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions : 
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support
    admiration       0.39      0.25      0.30      2117
     amusement       0.36      0.12      0.18      1180
         anger       0.38      0.03      0.05      1059
     annoyance       0.20      0.00      0.00      1687
      approval       0.18      0.00      0.01      2217
        caring       1.00      0.00      0.00       693
     confusion       0.04      0.00      0.00       980
     curiosity       0.30      0.13      0.18      1171
        desire       0.00      0.00      0.00       479
disappointment       0.00      0.00      0.00       898
   disapproval       0.20      0.01      0.02      1512
       disgust       0.00      0.00      0.00       633
 embarrassment       0.00      0.00      0.00       272
    excitement       0.19      0.01      0.02       592
          fear       0.00      0.00      0.00       343
     gratitude       0.60      0.53      0.57      1419
         grief       0.00      0.00      0.00        53
           joy       0.33      0.02      0.04       898
          love       0.43      0.30      0.35      1018
   nervousness       0.00      0.00      0.00       182
       neutral       0.35      0.93      0.50     11035
      optimism       0.50      0.00      0.00       915
         pride       0.00      0.00      0.00       165
   realization       0.00      0.00      0.00       942
        relief       0.00      0.00      0.00       173
       remorse       0.00      0.00      0.00       316
       sadness       0.18      0.01      0.01       713
      surprise       0.00      0.00      0.00       702
      accuracy                           0.36     34364
     macro avg       0.20      0.08      0.08     34364
  weighted avg       0.29      0.36      0.23     34364
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For sentiments : 
              precision    recall  f1-score   support
   ambiguous       0.47      0.18      0.26      3824
    negative       0.50      0.38      0.43      7700
     neutral       0.44      0.56      0.49     11191
    positive       0.59      0.65      0.62     11649
    accuracy                           0.51     34364
   macro avg       0.50      0.44      0.45     34364
weighted avg       0.51      0.51      0.49     34364

Part 3.8 Second embedding model

Using a better performing Multi-Layered Perceptron (the best model)
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions : 
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\metrics\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support
    admiration       0.47      0.26      0.34      2108
     amusement       0.37      0.07      0.12      1221
         anger       0.39      0.04      0.07      1042
     annoyance       0.19      0.02      0.04      1686
      approval       0.36      0.01      0.02      2270
        caring       0.24      0.01      0.02       715
     confusion       0.20      0.01      0.02       989
     curiosity       0.28      0.04      0.07      1202
        desire       0.00      0.00      0.00       379
disappointment       0.19      0.00      0.01       935
   disapproval       0.21      0.02      0.03      1657
       disgust       0.31      0.04      0.07       623
 embarrassment       0.00      0.00      0.00       271
    excitement       0.30      0.01      0.02       569
          fear       0.39      0.04      0.07       360
     gratitude       0.52      0.34      0.41      1396
         grief       0.00      0.00      0.00        61
           joy       0.22      0.02      0.04       798
          love       0.51      0.26      0.35       981
   nervousness       0.00      0.00      0.00       161
       neutral       0.34      0.93      0.50     11027
      optimism       0.28      0.03      0.06       915
         pride       0.00      0.00      0.00       127
   realization       0.00      0.00      0.00       971
        relief       0.00      0.00      0.00       137
       remorse       0.38      0.01      0.02       313
       sadness       0.24      0.06      0.10       765
      surprise       0.00      0.00      0.00       685
      accuracy                           0.35     34364
     macro avg       0.23      0.08      0.08     34364
  weighted avg       0.30      0.35      0.23     34364
C:\Users\Admin\anaconda3\envs\comp472\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For sentiments : 
              precision    recall  f1-score   support
   ambiguous       0.45      0.15      0.22      3824
    negative       0.45      0.40      0.42      7712
     neutral       0.40      0.53      0.46     10980
    positive       0.57      0.58      0.58     11848
    accuracy                           0.47     34364
   macro avg       0.47      0.41      0.42     34364
weighted avg       0.48      0.47      0.46     34364
 Using base MultiLayer Preceptron with default parameters
30449
C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions :

C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support

    admiration       0.50      0.55      0.52      2115
     amusement       0.56      0.62      0.58      1313
         anger       0.39      0.25      0.30      1081
     annoyance       0.28      0.05      0.08      1654
      approval       0.38      0.07      0.12      2263
        caring       0.29      0.07      0.11       698
     confusion       0.37      0.08      0.13       992
     curiosity       0.36      0.12      0.18      1189
        desire       0.42      0.21      0.28       405
disappointment       0.33      0.04      0.07       950
   disapproval       0.24      0.06      0.09      1538
       disgust       0.42      0.18      0.25       557
 embarrassment       0.45      0.02      0.03       288
    excitement       0.47      0.07      0.13       602
          fear       0.65      0.28      0.39       366
     gratitude       0.79      0.78      0.78      1404
         grief       0.00      0.00      0.00        65
           joy       0.38      0.26      0.31       869
          love       0.60      0.64      0.62      1040
   nervousness       0.00      0.00      0.00       148
       neutral       0.41      0.84      0.55     10906
      optimism       0.46      0.32      0.38       899
         pride       0.00      0.00      0.00       141
   realization       0.42      0.02      0.04       890
        relief       0.00      0.00      0.00       156
       remorse       0.43      0.47      0.45       316
       sadness       0.44      0.19      0.26       805
      surprise       0.44      0.28      0.34       714

      accuracy                           0.44     34364
     macro avg       0.37      0.23      0.25     34364
  weighted avg       0.42      0.44      0.37     34364

Confusion Matrix:
 [[1164   24    9    5   11    4    0    6    2    1    1    0    0    4
     1   39    0   36   79    0  676   21    0    1    0    1    1   29]
 [  44  809   11    8    5    0    4    2    4    1    3    1    0    0
     0   11    0   18   12    0  351    5    0    0    0    4    6   14]
 [  12   21  265   33    2    4    2   10    1    4   12   13    0    1
     5    8    0    4    6    0  670    3    0    0    0    1    2    2]
 [  26   44  105   76   15    3    5   11    2    6   31   22    2    1
     3   16    0    6   12    0 1230   10    0    2    0    5   11   10]
 [ 156   35   12    5  155   12    9   10    3    4   26    2    0    2
     6   14    0   22   36    0 1713   16    0    4    0    5    5   11]
 [  27    6    1    4    7   46    4    2    7    1   11    1    0    0
     0   15    0   11   15    0  480   39    0    1    0   13    6    1]
 [  21   18    6    2   11    1   77   42    1    2   12    0    0    2
     1    5    0    6    7    0  755    3    0    1    0    4    2   13]
 [  17   10   17    8    6    0   14  146    3    1    4    3    1    4
     2    5    0    4    8    0  906    6    0    0    0    1    1   22]
 [  11    8    1    0    8    2    1    6   87    0    0    1    0    1
     0    3    0    2   12    0  232   28    0    0    0    1    1    0]
 [  29   14   19    9    8    8    2    6    8   35   15   16    1    0
     2    3    0    5    9    0  685   14    0    1    0   12   40    9]
 [  29   23   28    5   27    6    9    6    1    6   85   10    0    3
     4   12    0   10   13    0 1214   17    0    1    0   12    9    8]
 [   5    4   35   16    3    0    0    2    4    3    6   98    1    1
     2    0    0    2    4    0  352    5    0    0    0    1    9    4]
 [   6    7    4   14    4    0    0    2    0    2    9    3    5    0
     0    1    0    1    1    0  213    1    0    1    0   11    2    1]
 [  81   23    4    1    4    1    0    7    3    0    1    0    0   44
     1   11    0   44   15    0  324    6    0    0    0    2    1   29]
 [   1    5    6    4    0    0    1    0    1    1    5    8    0    0
   101    0    0    0    1    0  225    3    0    0    0    0    4    0]
 [  97   12    0    2    2    5    2    1    0    0    1    1    0    0
     1 1090    0   37    4    0   99   25    0    2    0   20    2    1]
 [   2    2    1    0    0    0    0    1    0    1    0    0    0    0
     1    0    0    1    1    0   49    1    0    0    0    2    3    0]
 [  79  104    2    0    5    4    0    3    5    0    0    0    0    5
     0   25    0  223   57    0  329   14    0    0    0    1    4    9]
 [  65    5    0    0    1    1    0    0    1    0    1    0    0    1
     0    6    0   18  667    0  262    7    0    0    0    1    2    2]
 [   2    1    5    1    3    2    1    1    0    3    2    3    0    0
     1    2    0    0    0    0  115    1    0    0    0    2    3    0]
 [ 305  221  118   68   92   40   57  122   40   22  101   35    1   17
    16   67    0   71  126    0 9149   85    0    6    0   28   58   61]
 [  52   12    0    0   13   10    3    3   24    1    3    1    0    3
     0   12    0   12   11    0  447  285    0    2    0    0    1    4]
 [  27    2    0    1    2    0    0    0    1    0    1    0    0    0
     0    4    0    8    1    0   91    2    0    0    0    0    0    1]
 [  17   21    7    3   12    2    7    4    0    2   15    3    0    2
     5    4    0    8    6    0  709    7    0   20    0    7    7   22]
 [  11    1    2    0    2    3    1    0    0    1    0    0    0    0
     0   13    0   17    2    0  100    0    0    1    0    0    2    0]
 [   1    7    1    1    2    1    2    1    5    1    2    2    0    0
     0    5    0    1    0    0  117    5    0    2    0  150    9    1]
 [  10    8    6    1    6    3    2    0    4    7    4   11    0    0
     2    3    0    8    6    0  496    8    0    1    0   66  151    2]
 [  36    6   16    1    6    0    3   15    1    0    5    0    0    3
     2    4    0    5    3    0  403    1    0    2    0    1    1  200]]

C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For sentiments :

              precision    recall  f1-score   support

   ambiguous       0.44      0.25      0.32      3794
    negative       0.57      0.54      0.55      7787
     neutral       0.49      0.58      0.53     11022
    positive       0.68      0.69      0.68     11761

    accuracy                           0.57     34364
   macro avg       0.55      0.51      0.52     34364
weighted avg       0.57      0.57      0.56     34364

Confusion Matrix:
 [[ 949  520 1690  635]
 [ 314 4192 2312  969]
 [ 602 1779 6352 2289]
 [ 271  866 2534 8090]]



part 3.5: MLP with training
Using Multi-Layered Perceptron with the default parameters
C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions :

C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support

    admiration       0.44      0.37      0.40      2120
     amusement       0.42      0.20      0.27      1208
         anger       0.36      0.07      0.11      1018
     annoyance       0.11      0.00      0.00      1645
      approval       0.56      0.01      0.01      2131
        caring       0.58      0.02      0.03       705
     confusion       0.00      0.00      0.00      1047
     curiosity       0.28      0.02      0.04      1221
        desire       0.00      0.00      0.00       446
disappointment       0.25      0.00      0.01       898
   disapproval       0.18      0.01      0.01      1562
       disgust       0.42      0.03      0.06       559
 embarrassment       0.00      0.00      0.00       290
    excitement       0.25      0.00      0.01       585
          fear       0.00      0.00      0.00       375
     gratitude       0.70      0.67      0.68      1408
         grief       0.00      0.00      0.00        70
           joy       0.31      0.05      0.08       865
          love       0.57      0.42      0.48       956
   nervousness       0.00      0.00      0.00       173
       neutral       0.36      0.94      0.52     11199
      optimism       0.40      0.04      0.06       881
         pride       0.00      0.00      0.00       137
   realization       0.00      0.00      0.00       927
        relief       0.00      0.00      0.00       172
       remorse       0.33      0.01      0.01       298
       sadness       0.31      0.08      0.12       785
      surprise       0.00      0.00      0.00       683

      accuracy                           0.38     34364
     macro avg       0.24      0.10      0.10     34364
  weighted avg       0.33      0.38      0.26     34364

C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For sentiments :

              precision    recall  f1-score   support

   ambiguous       0.45      0.09      0.14      3816
    negative       0.46      0.51      0.48      7661
     neutral       0.47      0.48      0.47     10953
    positive       0.59      0.69      0.64     11934

    accuracy                           0.52     34364
   macro avg       0.49      0.44      0.43     34364
weighted avg       0.51      0.52      0.50     34364

Part 3.6 with parametrized MLP
Using a better performing Multi-Layered Perceptron
C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions :

C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support

    admiration       0.46      0.35      0.40      2143
     amusement       0.48      0.13      0.20      1191
         anger       0.28      0.07      0.11      1022
     annoyance       0.27      0.01      0.02      1687
      approval       0.44      0.01      0.03      2275
        caring       0.37      0.02      0.04       695
     confusion       0.00      0.00      0.00       988
     curiosity       0.30      0.06      0.10      1124
        desire       0.67      0.00      0.01       448
disappointment       0.14      0.00      0.00       914
   disapproval       0.25      0.03      0.05      1561
       disgust       0.26      0.04      0.06       567
 embarrassment       0.00      0.00      0.00       296
    excitement       0.28      0.02      0.03       618
          fear       0.75      0.02      0.03       364
     gratitude       0.74      0.67      0.70      1396
         grief       0.00      0.00      0.00        63
           joy       0.34      0.05      0.08       897
          love       0.67      0.33      0.44       987
   nervousness       0.00      0.00      0.00       149
       neutral       0.36      0.93      0.51     11182
      optimism       0.36      0.06      0.10       854
         pride       0.00      0.00      0.00       140
   realization       0.00      0.00      0.00       906
        relief       0.00      0.00      0.00       161
       remorse       0.50      0.05      0.09       291
       sadness       0.28      0.10      0.15       757
      surprise       0.24      0.02      0.04       688

      accuracy                           0.38     34364
     macro avg       0.30      0.11      0.11     34364
  weighted avg       0.35      0.38      0.26     34364

C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For sentiments :

              precision    recall  f1-score   support

   ambiguous       0.45      0.08      0.13      3636
    negative       0.47      0.48      0.48      7711
     neutral       0.46      0.52      0.49     11210
    positive       0.60      0.67      0.63     11807

    accuracy                           0.52     34364
   macro avg       0.49      0.44      0.43     34364
weighted avg       0.51      0.52      0.50     34364

 Using base MultiLayer Preceptron with default parameters
30449
C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions :

C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support

    admiration       0.50      0.55      0.52      2115
     amusement       0.56      0.62      0.58      1313
         anger       0.39      0.25      0.30      1081
     annoyance       0.28      0.05      0.08      1654
      approval       0.38      0.07      0.12      2263
        caring       0.29      0.07      0.11       698
     confusion       0.37      0.08      0.13       992
     curiosity       0.36      0.12      0.18      1189
        desire       0.42      0.21      0.28       405
disappointment       0.33      0.04      0.07       950
   disapproval       0.24      0.06      0.09      1538
       disgust       0.42      0.18      0.25       557
 embarrassment       0.45      0.02      0.03       288
    excitement       0.47      0.07      0.13       602
          fear       0.65      0.28      0.39       366
     gratitude       0.79      0.78      0.78      1404
         grief       0.00      0.00      0.00        65
           joy       0.38      0.26      0.31       869
          love       0.60      0.64      0.62      1040
   nervousness       0.00      0.00      0.00       148
       neutral       0.41      0.84      0.55     10906
      optimism       0.46      0.32      0.38       899
         pride       0.00      0.00      0.00       141
   realization       0.42      0.02      0.04       890
        relief       0.00      0.00      0.00       156
       remorse       0.43      0.47      0.45       316
       sadness       0.44      0.19      0.26       805
      surprise       0.44      0.28      0.34       714

      accuracy                           0.44     34364
     macro avg       0.37      0.23      0.25     34364
  weighted avg       0.42      0.44      0.37     34364

Confusion Matrix:
 [[1164   24    9    5   11    4    0    6    2    1    1    0    0    4
     1   39    0   36   79    0  676   21    0    1    0    1    1   29]
 [  44  809   11    8    5    0    4    2    4    1    3    1    0    0
     0   11    0   18   12    0  351    5    0    0    0    4    6   14]
 [  12   21  265   33    2    4    2   10    1    4   12   13    0    1
     5    8    0    4    6    0  670    3    0    0    0    1    2    2]
 [  26   44  105   76   15    3    5   11    2    6   31   22    2    1
     3   16    0    6   12    0 1230   10    0    2    0    5   11   10]
 [ 156   35   12    5  155   12    9   10    3    4   26    2    0    2
     6   14    0   22   36    0 1713   16    0    4    0    5    5   11]
 [  27    6    1    4    7   46    4    2    7    1   11    1    0    0
     0   15    0   11   15    0  480   39    0    1    0   13    6    1]
 [  21   18    6    2   11    1   77   42    1    2   12    0    0    2
     1    5    0    6    7    0  755    3    0    1    0    4    2   13]
 [  17   10   17    8    6    0   14  146    3    1    4    3    1    4
     2    5    0    4    8    0  906    6    0    0    0    1    1   22]
 [  11    8    1    0    8    2    1    6   87    0    0    1    0    1
     0    3    0    2   12    0  232   28    0    0    0    1    1    0]
 [  29   14   19    9    8    8    2    6    8   35   15   16    1    0
     2    3    0    5    9    0  685   14    0    1    0   12   40    9]
 [  29   23   28    5   27    6    9    6    1    6   85   10    0    3
     4   12    0   10   13    0 1214   17    0    1    0   12    9    8]
 [   5    4   35   16    3    0    0    2    4    3    6   98    1    1
     2    0    0    2    4    0  352    5    0    0    0    1    9    4]
 [   6    7    4   14    4    0    0    2    0    2    9    3    5    0
     0    1    0    1    1    0  213    1    0    1    0   11    2    1]
 [  81   23    4    1    4    1    0    7    3    0    1    0    0   44
     1   11    0   44   15    0  324    6    0    0    0    2    1   29]
 [   1    5    6    4    0    0    1    0    1    1    5    8    0    0
   101    0    0    0    1    0  225    3    0    0    0    0    4    0]
 [  97   12    0    2    2    5    2    1    0    0    1    1    0    0
     1 1090    0   37    4    0   99   25    0    2    0   20    2    1]
 [   2    2    1    0    0    0    0    1    0    1    0    0    0    0
     1    0    0    1    1    0   49    1    0    0    0    2    3    0]
 [  79  104    2    0    5    4    0    3    5    0    0    0    0    5
     0   25    0  223   57    0  329   14    0    0    0    1    4    9]
 [  65    5    0    0    1    1    0    0    1    0    1    0    0    1
     0    6    0   18  667    0  262    7    0    0    0    1    2    2]
 [   2    1    5    1    3    2    1    1    0    3    2    3    0    0
     1    2    0    0    0    0  115    1    0    0    0    2    3    0]
 [ 305  221  118   68   92   40   57  122   40   22  101   35    1   17
    16   67    0   71  126    0 9149   85    0    6    0   28   58   61]
 [  52   12    0    0   13   10    3    3   24    1    3    1    0    3
     0   12    0   12   11    0  447  285    0    2    0    0    1    4]
 [  27    2    0    1    2    0    0    0    1    0    1    0    0    0
     0    4    0    8    1    0   91    2    0    0    0    0    0    1]
 [  17   21    7    3   12    2    7    4    0    2   15    3    0    2
     5    4    0    8    6    0  709    7    0   20    0    7    7   22]
 [  11    1    2    0    2    3    1    0    0    1    0    0    0    0
     0   13    0   17    2    0  100    0    0    1    0    0    2    0]
 [   1    7    1    1    2    1    2    1    5    1    2    2    0    0
     0    5    0    1    0    0  117    5    0    2    0  150    9    1]
 [  10    8    6    1    6    3    2    0    4    7    4   11    0    0
     2    3    0    8    6    0  496    8    0    1    0   66  151    2]
 [  36    6   16    1    6    0    3   15    1    0    5    0    0    3
     2    4    0    5    3    0  403    1    0    2    0    1    1  200]]



part 3.5: MLP with training
Using Multi-Layered Perceptron with the default parameters
C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions :

C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support

    admiration       0.44      0.37      0.40      2120
     amusement       0.42      0.20      0.27      1208
         anger       0.36      0.07      0.11      1018
     annoyance       0.11      0.00      0.00      1645
      approval       0.56      0.01      0.01      2131
        caring       0.58      0.02      0.03       705
     confusion       0.00      0.00      0.00      1047
     curiosity       0.28      0.02      0.04      1221
        desire       0.00      0.00      0.00       446
disappointment       0.25      0.00      0.01       898
   disapproval       0.18      0.01      0.01      1562
       disgust       0.42      0.03      0.06       559
 embarrassment       0.00      0.00      0.00       290
    excitement       0.25      0.00      0.01       585
          fear       0.00      0.00      0.00       375
     gratitude       0.70      0.67      0.68      1408
         grief       0.00      0.00      0.00        70
           joy       0.31      0.05      0.08       865
          love       0.57      0.42      0.48       956
   nervousness       0.00      0.00      0.00       173
       neutral       0.36      0.94      0.52     11199
      optimism       0.40      0.04      0.06       881
         pride       0.00      0.00      0.00       137
   realization       0.00      0.00      0.00       927
        relief       0.00      0.00      0.00       172
       remorse       0.33      0.01      0.01       298
       sadness       0.31      0.08      0.12       785
      surprise       0.00      0.00      0.00       683

      accuracy                           0.38     34364
     macro avg       0.24      0.10      0.10     34364
  weighted avg       0.33      0.38      0.26     34364

C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For sentiments :

              precision    recall  f1-score   support

   ambiguous       0.45      0.09      0.14      3816
    negative       0.46      0.51      0.48      7661
     neutral       0.47      0.48      0.47     10953
    positive       0.59      0.69      0.64     11934

    accuracy                           0.52     34364
   macro avg       0.49      0.44      0.43     34364
weighted avg       0.51      0.52      0.50     34364

Part 3.6 with parametrized MLP
Using a better performing Multi-Layered Perceptron
C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For emotions :

C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
C:\Users\athome\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
                precision    recall  f1-score   support

    admiration       0.46      0.35      0.40      2143
     amusement       0.48      0.13      0.20      1191
         anger       0.28      0.07      0.11      1022
     annoyance       0.27      0.01      0.02      1687
      approval       0.44      0.01      0.03      2275
        caring       0.37      0.02      0.04       695
     confusion       0.00      0.00      0.00       988
     curiosity       0.30      0.06      0.10      1124
        desire       0.67      0.00      0.01       448
disappointment       0.14      0.00      0.00       914
   disapproval       0.25      0.03      0.05      1561
       disgust       0.26      0.04      0.06       567
 embarrassment       0.00      0.00      0.00       296
    excitement       0.28      0.02      0.03       618
          fear       0.75      0.02      0.03       364
     gratitude       0.74      0.67      0.70      1396
         grief       0.00      0.00      0.00        63
           joy       0.34      0.05      0.08       897
          love       0.67      0.33      0.44       987
   nervousness       0.00      0.00      0.00       149
       neutral       0.36      0.93      0.51     11182
      optimism       0.36      0.06      0.10       854
         pride       0.00      0.00      0.00       140
   realization       0.00      0.00      0.00       906
        relief       0.00      0.00      0.00       161
       remorse       0.50      0.05      0.09       291
       sadness       0.28      0.10      0.15       757
      surprise       0.24      0.02      0.04       688

      accuracy                           0.38     34364
     macro avg       0.30      0.11      0.11     34364
  weighted avg       0.35      0.38      0.26     34364

C:\Users\athome\anaconda3\lib\site-packages\sklearn\neural_network\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.
  warnings.warn(
For sentiments :

              precision    recall  f1-score   support

   ambiguous       0.45      0.08      0.13      3636
    negative       0.47      0.48      0.48      7711
     neutral       0.46      0.52      0.49     11210
    positive       0.60      0.67      0.63     11807

    accuracy                           0.52     34364
   macro avg       0.49      0.44      0.43     34364
weighted avg       0.51      0.52      0.50     34364

